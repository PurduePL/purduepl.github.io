---
layout: post
speaker: "Adhitha Dias"
title: "SparseAuto: An Auto-Scheduler for Sparse Tensor Computations Using Recursive Loop Nest Restructuring (OOPSLA 2024 Practice talk)"
time: 12:15p EST
location: "WANG 1004"
category: seminar
invited: false
link_abstract: true
bio: "Adhitha Dias is a fourth-year PhD student working with Prof. Milind Kulkarni. He works on compiler transformations for sparse tensor algebra."
---
Automated code generation and performance enhancements for sparse tensor algebra have become essential
in many real-world applications, such as quantum computing, physical simulations, computational chemistry,
and machine learning. General sparse tensor algebra compilers are not always versatile enough to generate
asymptotically optimal code for sparse tensor contractions. This paper shows how to generate asymptotically
better schedules for complex sparse tensor expressions using kernel fission and fusion. We present generalized
loop restructuring transformations to reduce asymptotic time complexity and
memory footprint.

Furthermore, we present an auto-scheduler that uses a partially ordered set (poset)-based cost model that
uses both time and auxiliary memory complexities to prune the search space of schedules. In addition, we
highlight the use of Satisfiability Module Theory (SMT) solvers in sparse auto-schedulers to approximate the
Pareto frontier of better schedules to the smallest number of possible schedules, with user-defined constraints
available at compile-time. Finally, we show that our auto-scheduler can select better-performing schedules
and generate code for them. Our results show that the auto-scheduler provided schedules achieve orders of magnitude speedup compared to the code generated by the Tensor Algebra Compiler (TACO) for several
computations on different real-world tensors.
